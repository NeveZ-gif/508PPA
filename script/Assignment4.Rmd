---
title: "Assignment4"
author: "Neve/Viva/Yaohan"
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: yes
    toc: yes
    theme: flatly
    toc_float: yes
    code_folding: hide
    number_sections: no
  pdf_document:
    toc: yes
---

```{=html}
<style>
.kable thead tr th, .table thead tr th {
  text-align: left !important;}
table.kable, table.table {
  width: 100% !important;}
  body {
  line-height: 1.6;
  font-size: 16px
}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  dpi = 150)
options(scipen = 999)

if(!require(pacman)){install.packages("pacman"); library(pacman)}
p_load(tidyverse, sf, units, nngeo, tmap, tinytex, kableExtra, janitor, classInt,
       patchwork, here, tidycensus, lwgeom, lsr, haven, descr, RColorBrewer, stargazer,
       car, FNN, GGally, MASS, ISLR2, spdep, caret, ckanr, grid, gridExtra, ggcorrplot,
       jtools, broom, tufte, rmarkdown, corrr, RSocrata, viridis, spatstat, raster, knitr,
       classInt, jsonlite)

library(conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
```

```{r clean data}
dat <- read_csv(here::here('data/raw/NIJ_s_Recidivism_Challenge_Full_Dataset_20240418.csv'))
glimpse(dat)
dat$Recidivism_Within_3years

```

# Discussion
- sensitivity：high cost, ruin others life
- specificity：let go of criminals

# Plot of Variables
**continuous**
- Supervision_Risk_Score_First
- DrugTests_THC_Positive
- DrugTests_Cocaine_Positive
- DrugTests_Meth_Positive
- DrugTests_Other_Positive
- Percent_Days_Employed

**Categorical**
- Gender
- Race
- Age_at_Release
- Gang_Affiliated
- Education_Level
- Dependents
- Prison_Offense
- Prison_Years
- Prior_Arrest_Episodes_Felony 
- Prior_Arrest_Episodes_Misd
- Prior_Conviction_Episodes_Felony
- Prior_Conviction_Episodes_Misd
- Condition_MH_SA
- Condition_Cog_Ed
- Condition_Other
- Delinquency_Reports 
- Program_Attendances
- Program_UnexcusedAbsences
- Employment_Exempt

```{r category}
table(dat$Supervision_Level_First)



```

```{r continuous}




```




# Model Develop

# Result Interpretation
1. Model Result 

2. Most Risky Person

# ROC Curve

The ROC curve, gives us another visual "goodness of fit" metric. One that is a bit more tricky. You want to have a curve that is "above" the y=x line, which is where your prediction rates for positives and negatives are "no better than a coin flip". If it's too "square" - you are probably over fit. The Area-Under-The-Curve or "AUC" calculation below will help guide your understanding of the ROC curve

```{r auc, message = FALSE, warning = FALSE}
auc(testProbs$Outcome, testProbs$Probs)
```

```{r roc_curve, warning = FALSE, message = FALSE}
ggplot(testProbs, aes(d = as.numeric(Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - clickModel")
```

# Confusion Matrix

Each threshold (e.g. a probability above which a prediction is a "click" and below which it's a "no click") has it's own rate of error. These errors can be classified in four ways for a binary model.

A "confusion matrix" for the threshold of 50% shows us the rate at which we got True Positives (aka Sensitivity), False Positives, True Negatives (aka Specificity) and False Negatives for that threshold.

```{r thresholds}
testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$Probs > 0.5 , 1, 0)))
```

```{r confusion_matrix}
caret::confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                       positive = "1")
```

# Sensitivity and Specificity

# Prediction

## Error

## Summary by Race

## Equity Discussion

# Cost-Benifit Analysis

# Conclusion




